openapi: 3.0.3
info:
  title: ReliAPI
  description: 'Reliability layer for API calls: retries, caching, dedup, circuit breakers.'
  version: 1.1.0
  contact:
    name: KikuAI-Lab
    url: https://github.com/KikuAI-Lab/reliapi
    email: dev@kikuai.dev
  license:
    name: MIT
    url: https://opensource.org/licenses/MIT
servers:
  - url: https://reliapi.kikuai.dev
    description: Production server
paths:
  /health:
    get:
      summary: Health Check
      description: Health check endpoint for monitoring. Returns 200 when the service is healthy.
      operationId: HealthCheck
      responses:
        '200':
          description: Service is healthy
          content:
            application/json:
              schema:
                type: object
                properties:
                  status:
                    type: string
                    example: healthy
  /v1/proxy/http:
    post:
      summary: Proxy HTTP Request
      description: |
        Universal HTTP proxy endpoint for any HTTP API. Supports retries, circuit breaker, cache, and idempotency.
        
        Key Features:
        - Automatic Retries - Failed requests are retried with exponential backoff
        - Circuit Breaker - Stops making requests to failing services to prevent cascading failures
        - Caching - GET requests are cached to reduce API calls and improve speed
        - Idempotency - Duplicate requests with the same key execute only once
        - Error Handling - Normalized error responses with retry guidance
      operationId: ProxyHTTPv1
      tags:
        - Proxy
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/HTTPProxyRequest'
            example:
              target: my_api
              method: GET
              path: /users/123
              headers:
                Custom-Header: value
                Authorization: Bearer token123
              query:
                include: profile
                page: 1
                limit: 10
              body: null
              idempotency_key: req-123-unique
              cache: 300
      responses:
        '200':
          description: Successful HTTP proxy request
          headers:
            X-Request-ID:
              schema:
                type: string
              description: Unique request identifier
            X-Cache-Hit:
              schema:
                type: string
              description: Whether response was from cache (true/false)
            X-Retries:
              schema:
                type: integer
              description: Number of retries performed
            X-Duration-MS:
              schema:
                type: integer
              description: Request duration in milliseconds
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPProxySuccessResponse'
        '400':
          description: Invalid request
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
        '422':
          description: Validation Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPValidationError'
        '429':
          description: Rate limit exceeded
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
        '500':
          description: Internal server error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
        '503':
          description: Upstream API error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
  /v1/proxy/llm:
    post:
      summary: Proxy LLM Request
      description: |
        LLM proxy endpoint with idempotency, budget caps, and caching. Make idempotent LLM API calls with predictable costs.
        
        Supports OpenAI, Anthropic, and Mistral providers. Set stream=true for Server-Sent Events (SSE) streaming.
        
        Key Features:
        - Prevents duplicate charges with idempotency keys
        - Saves money with automatic caching
        - Controls spending with budget caps
        - Handles failures with automatic retries
        - Tracks costs in USD
      operationId: ProxyLLMv1
      tags:
        - Proxy
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/LLMProxyRequest'
            example:
              target: openai
              messages:
                - role: user
                  content: What is the capital of France?
              model: gpt-4o-mini
              max_tokens: 100
              temperature: 0.7
              stream: false
              idempotency_key: unique-request-id-123
              cache: 3600
      responses:
        '200':
          description: Successful LLM proxy request
          headers:
            X-Request-ID:
              schema:
                type: string
              description: Unique request identifier
            X-Cache-Hit:
              schema:
                type: string
              description: Whether response was from cache (true/false)
            X-Retries:
              schema:
                type: integer
              description: Number of retries performed
            X-Duration-MS:
              schema:
                type: integer
              description: Request duration in milliseconds
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/LLMProxySuccessResponse'
        '400':
          description: Budget cap exceeded or client error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
        '403':
          description: Account or IP banned
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
        '422':
          description: Validation Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPValidationError'
        '429':
          description: Rate limit exceeded
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
        '500':
          description: Internal server error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
  /v1/rapidapi/status:
    get:
      summary: RapidAPI Integration Status
      description: Check the status of RapidAPI integration, including subscription tier detection, rate limiting, and integration health.
      operationId: GetRapidAPIStatusv1
      tags:
        - RapidAPI
      responses:
        '200':
          description: RapidAPI integration status
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RapidAPIStatusResponse'
        '401':
          description: Unauthorized
          content:
            application/json:
              schema:
                type: object
                properties:
                  error:
                    type: string
                    example: Unauthorized
                  message:
                    type: string
                    example: Invalid X-RapidAPI-Key header
  # Legacy endpoints (deprecated)
  /proxy/http:
    post:
      summary: '[DEPRECATED] Proxy HTTP Request'
      description: |
        **DEPRECATED**: Use `/v1/proxy/http` instead. This endpoint will be removed in 6 months.
        
        Universal HTTP proxy endpoint for any HTTP API.
      operationId: ProxyHTTPLegacy
      deprecated: true
      tags:
        - Legacy
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/HTTPProxyRequest'
      responses:
        '200':
          description: Successful HTTP proxy request
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HTTPProxySuccessResponse'
  /proxy/llm:
    post:
      summary: '[DEPRECATED] Proxy LLM Request'
      description: |
        **DEPRECATED**: Use `/v1/proxy/llm` instead. This endpoint will be removed in 6 months.
        
        LLM proxy endpoint with idempotency, budget caps, and caching.
      operationId: ProxyLLMLegacy
      deprecated: true
      tags:
        - Legacy
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/LLMProxyRequest'
      responses:
        '200':
          description: Successful LLM proxy request
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/LLMProxySuccessResponse'
components:
  schemas:
    HTTPProxyRequest:
      type: object
      required:
        - target
        - method
        - path
      properties:
        target:
          type: string
          description: Target name from config.yaml (e.g., 'my_api')
          example: my_api
        method:
          type: string
          description: 'HTTP method: GET, POST, PUT, DELETE, PATCH, HEAD, OPTIONS'
          enum:
            - GET
            - POST
            - PUT
            - DELETE
            - PATCH
            - HEAD
            - OPTIONS
          example: GET
        path:
          type: string
          description: API path (e.g., '/users/123' or '/api/v1/data')
          example: /users/123
        headers:
          type: object
          description: HTTP headers to include in request
          additionalProperties:
            type: string
          example:
            Custom-Header: value
            Authorization: Bearer token123
        query:
          type: object
          description: 'Query parameters (e.g., {''page'': 1, ''limit'': 10})'
          additionalProperties: true
          example:
            include: profile
            page: 1
            limit: 10
        body:
          type: string
          description: Request body as JSON string (for POST/PUT/PATCH)
          nullable: true
          example: null
        idempotency_key:
          type: string
          description: Idempotency key for request coalescing. Concurrent requests with same key execute once.
          nullable: true
          example: req-123-unique
        cache:
          type: integer
          description: Cache TTL in seconds (overrides config default). Only applies to GET/HEAD requests.
          nullable: true
          example: 300
    HTTPProxySuccessResponse:
      type: object
      required:
        - success
        - data
        - meta
      properties:
        success:
          type: boolean
          example: true
        data:
          type: object
          required:
            - status_code
          properties:
            status_code:
              type: integer
              example: 200
            headers:
              type: object
              additionalProperties:
                type: string
              example:
                Content-Type: application/json
                X-RateLimit-Remaining: "99"
            body:
              description: Response body (parsed JSON if Content-Type is application/json)
              oneOf:
                - type: object
                - type: string
          example:
            id: 123
            name: John Doe
            email: john@example.com
        meta:
          $ref: '#/components/schemas/RequestMeta'
    LLMProxyRequest:
      type: object
      required:
        - target
        - messages
      properties:
        target:
          type: string
          description: LLM target name from config.yaml (e.g., 'openai', 'anthropic', 'mistral')
          enum:
            - openai
            - anthropic
            - mistral
          example: openai
        messages:
          type: array
          description: 'Messages list with ''role'' and ''content'''
          items:
            type: object
            required:
              - role
              - content
            properties:
              role:
                type: string
                enum:
                  - user
                  - assistant
                  - system
                example: user
              content:
                type: string
                example: What is the capital of France?
          example:
            - role: user
              content: What is the capital of France?
        model:
          type: string
          description: Model name (e.g., 'gpt-4o-mini', 'claude-3-haiku').
          nullable: true
          example: gpt-4o-mini
        max_tokens:
          type: integer
          description: Maximum tokens in response
          nullable: true
          example: 100
        temperature:
          type: number
          description: Temperature for sampling (0.0-2.0)
          minimum: 0
          maximum: 2
          nullable: true
          example: 0.7
        top_p:
          type: number
          description: Top-p sampling parameter (0.0-1.0)
          minimum: 0
          maximum: 1
          nullable: true
          example: 1.0
        stop:
          type: array
          description: Stop sequences
          items:
            type: string
          nullable: true
          example:
            - "\n"
            - END
        stream:
          type: boolean
          description: Streaming mode. If true, returns Server-Sent Events (SSE) stream.
          default: false
          example: false
        idempotency_key:
          type: string
          description: Idempotency key for request coalescing.
          nullable: true
          example: unique-request-id-123
        cache:
          type: integer
          description: Cache TTL in seconds.
          nullable: true
          example: 3600
    LLMProxySuccessResponse:
      type: object
      required:
        - success
        - data
        - meta
      properties:
        success:
          type: boolean
          example: true
        data:
          type: object
          required:
            - content
            - role
          properties:
            content:
              type: string
              description: The AI's response text
              example: The capital of France is Paris.
            role:
              type: string
              example: assistant
            finish_reason:
              type: string
              example: stop
            usage:
              type: object
              properties:
                prompt_tokens:
                  type: integer
                  example: 12
                completion_tokens:
                  type: integer
                  example: 8
                total_tokens:
                  type: integer
                  example: 20
        meta:
          allOf:
            - $ref: '#/components/schemas/RequestMeta'
            - type: object
              properties:
                provider:
                  type: string
                  example: openai
                model:
                  type: string
                  example: gpt-4o-mini
                cost_usd:
                  type: number
                  format: float
                  description: Actual cost of this request in USD
                  example: 0.000012
                cost_estimate_usd:
                  type: number
                  format: float
                  description: Estimated cost before request
                  example: 0.000015
    ErrorResponse:
      type: object
      required:
        - success
        - error
        - meta
      properties:
        success:
          type: boolean
          example: false
        error:
          $ref: '#/components/schemas/ErrorDetail'
        meta:
          $ref: '#/components/schemas/RequestMeta'
    ErrorDetail:
      type: object
      required:
        - type
        - code
        - message
        - retryable
        - status_code
      properties:
        type:
          type: string
          description: Error type
          enum:
            - client_error
            - upstream_error
            - rate_limit_error
            - budget_error
            - circuit_breaker_error
            - timeout_error
            - internal_error
          example: client_error
        code:
          type: string
          description: Error code
          example: INVALID_REQUEST
        message:
          type: string
          description: Human-readable error message
          example: "Missing required parameter: target"
        retryable:
          type: boolean
          description: Whether the request can be retried
          example: false
        target:
          type: string
          description: Target API name (if applicable)
          nullable: true
          example: my_api
        status_code:
          type: integer
          description: HTTP status code
          example: 400
    RequestMeta:
      type: object
      required:
        - retries
        - duration_ms
        - request_id
      properties:
        target:
          type: string
          description: Target API name
          nullable: true
          example: my_api
        cache_hit:
          type: boolean
          description: Whether response came from cache
          example: false
        idempotent_hit:
          type: boolean
          description: Whether this was a duplicate request
          example: false
        retries:
          type: integer
          description: Number of retry attempts made
          example: 0
        duration_ms:
          type: integer
          description: Request duration in milliseconds
          example: 145
        request_id:
          type: string
          description: Unique identifier for tracking
          example: req_1234567890_abc12345
    RapidAPIStatusResponse:
      type: object
      required:
        - status
        - tier
      properties:
        status:
          type: string
          description: Integration status
          example: configured
        tier:
          type: string
          description: Subscription tier
          enum:
            - free
            - developer
            - pro
            - enterprise
          example: free
        usage:
          type: object
          properties:
            requests_count:
              type: integer
              example: 0
            requests_limit:
              type: integer
              example: 1000
            period:
              type: string
              example: month
            usage_percent:
              type: number
              format: float
              example: 0.0
        redis_connected:
          type: boolean
          example: true
        api_configured:
          type: boolean
          example: false
    HTTPValidationError:
      type: object
      properties:
        detail:
          type: array
          items:
            $ref: '#/components/schemas/ValidationError'
    ValidationError:
      type: object
      required:
        - loc
        - msg
        - type
      properties:
        loc:
          type: array
          items:
            oneOf:
              - type: string
              - type: integer
          title: Location
        msg:
          type: string
          title: Message
        type:
          type: string
          title: Error Type
tags:
  - name: Proxy
    description: Core proxy endpoints for HTTP and LLM requests
  - name: RapidAPI
    description: RapidAPI integration endpoints
  - name: Legacy
    description: Deprecated endpoints (will be removed in 6 months)
